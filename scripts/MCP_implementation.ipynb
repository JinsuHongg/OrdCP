{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cca38c4",
   "metadata": {},
   "source": [
    "# Mondrian Conformal Prediction with Class-wise Coverage Guarantees\n",
    "## 1. Overview\n",
    "This implementation focuses on Mondrian Conformal Prediction, a method that provides reliable prediction intervals while maintaining class-specific coverage guarantees. The approach ensures that predictive uncertainty is accurately quantified for each individual class.\n",
    "## 2. Methodology\n",
    "The non-conformity scores are calculated using cumulative probability summation, which provides a robust measure of prediction reliability. The method proceeds as follows:\n",
    "\n",
    "1. For each class, we compute non-conformity scores based on the cumulative probability distribution\n",
    "2. These scores maintain separate calibration for each class label\n",
    "3. The result is a prediction set that guarantees the desired coverage level within each class\n",
    "\n",
    "The non-conformity score Î± for an example (x, y) is computed as:\n",
    "$$\n",
    "C_i = \\sum_{k=1}^{K}  |y_{i,k} - \\hat{h}_{i,k}(x_i)|,\\; i \\in X_{calibration}\n",
    "$$\n",
    "\n",
    "## 3. Notation and Example\n",
    "#### 1) Variable Definitions\n",
    "#### Let:\n",
    "\n",
    "1. $K$ represent the total number of classes\n",
    "2. $y_{i,k}$ denote the true label for the $i$-th instance in class $k$\n",
    "3. $\\hat{h}_{i,k}$ represent our predicted probability for the $i$-th instance in class $k$\n",
    "\n",
    "#### 2) Example Illustration\n",
    "Consider a binary classification case where we represent labels in cumulative binary form:\n",
    "#### True Labels\n",
    "$y = [1, 1, 0, 0]$ represents class 2, where:\n",
    "\n",
    "- 1's indicate the classes up to and including the true class\n",
    "- 0's indicate the classes above the true class\n",
    "\n",
    "#### 3) Predicted Probabilities\n",
    "$\\hat{h} = [0.96, 0.82, 0.45, 0.15]$ represents our model's predictions, where:\n",
    "\n",
    "- Each value represents the predicted probability for the corresponding position\n",
    "- Values typically decrease as we move through the cumulative binary representation\n",
    "\n",
    "#### 4) Mathematical Representation\n",
    "For this example:\n",
    "\n",
    "- $K = 4$ (number of positions in the vector)\n",
    "- $i$ represents a single instance\n",
    "- Each position $k \\in {1,2,3,4}$ has a corresponding $y_{i,k}$ and $\\hat{h}_{i,k}$\n",
    "\n",
    "$$\n",
    "C = |1 - 0.96| + |1 - 0.82| + |0 - 0.45| + |0 - 0.15|\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0bc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from training import test_loop\n",
    "from training import SolarFlSets, HSS2, TSS, F1Pos, HSS_multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fd2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCP:\n",
    "    def __init__(self, arr: np.ndarray = None, calset: int = 3):\n",
    "        \"\"\"\n",
    "        Mondrian Conformal Prediction (MCP) Non-Conformity Measure (NCM).\n",
    "        \n",
    "        Args:\n",
    "            arr (np.ndarray): A 2D NumPy array where:\n",
    "                - Columns 0 to 3: Model outputs from sigmoid (probabilities).\n",
    "                - Column 4: Predictive values (integers).\n",
    "                - Column 5: Ground truth labels (integers 0-3).\n",
    "            calset (int): Calibration set index (not used in this function but stored for future use).\n",
    "        \"\"\"\n",
    "        self.arr = arr  # Shape: (N, 6), where N is the number of samples\n",
    "        self.calset = calset\n",
    "\n",
    "    def threshold(self, q = 0.1):\n",
    "        \"\"\"\n",
    "        Compute non-conformity scores and separate them by class.\n",
    "        Args:\n",
    "        q: percentile of the empirical distribution\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: \n",
    "            Non-conformity scores for each class (0, 1, 2, 3).\n",
    "        \"\"\"\n",
    "        if self.arr is None:\n",
    "            raise ValueError(\"Input array (arr) is None. Please provide data.\")\n",
    "\n",
    "        num_classes = 4  # Assuming 4 ordinal classes\n",
    "        labels = self.arr[:, 5].astype(int)  # Extract ground truth labels (column 5)\n",
    "\n",
    "        # Convert ground truth labels to cumulative binary form\n",
    "        binary_labels = (labels[:, None] >= np.arange(num_classes)).astype(np.float32)\n",
    "\n",
    "        # Compute non-conformity score as absolute difference\n",
    "        ncm = np.abs(self.arr[:, :num_classes] - binary_labels)\n",
    "\n",
    "        # Efficiently filter samples per class\n",
    "        class_ncm = [ncm[labels == c] for c in range(num_classes)]\n",
    "        self.dist = tuple(class_ncm)  # Return as tuple (class_0, class_1, class_2, class_3)\n",
    "        \n",
    "        # define threshold for each class\n",
    "        thres_cls = [ np.quantile(self.dist[c], q) for c in range(num_classes) ]\n",
    "        return thres_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d29ec5-c725-4c0d-8050-91d486450c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_file = '24image_multi_GOES_classification_Partition3.csv'\n",
    "test_file = '24image_multi_GOES_classification_Partition4.csv'\n",
    "\n",
    "        \n",
    "print('--------------------------------------------------------------------------------')\n",
    "print(f'Train: ({train}), Test: {test}')\n",
    "print(f\"Initial learning rate: {lr:.1e}, decay value: {wt:.1e}\")\n",
    "print('--------------------------------------------------------------------------------')\n",
    "\n",
    "# train set\n",
    "df_train = pd.DataFrame([], columns = ['Timestamp', 'GOES_cls', 'Label'])\n",
    "for partition in train_list:\n",
    "    d = pd.read_csv(file_path + partition)\n",
    "    df_train = pd.concat([df_train, d])\n",
    "\n",
    "# test set and calibration set\n",
    "df_test = pd.read_csv(file_path + test_file)\n",
    "\n",
    "# string to datetime\n",
    "df_train['Timestamp'] = pd.to_datetime(df_train['Timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "df_test['Timestamp'] = pd.to_datetime(df_test['Timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# training data loader\n",
    "# over/under sampling\n",
    "data_training, imbalance_ratio = oversample_func(df = df_train, img_dir = img_dir, channel = channel_tag, norm = True)\n",
    "\n",
    "# validation data loader\n",
    "data_testing = SolarFlSets(annotations_df = df_test, img_dir = img_dir, channel = channel_tag, normalization = True)\n",
    "train_dataloader = DataLoader(data_training, batch_size = batch_size, shuffle = True) # num_workers = 0, pin_memory = True, \n",
    "test_dataloader = DataLoader(data_testing, batch_size = batch_size, shuffle = False) # num_workers = 0, pin_memory = True, \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b7348-12ae-4879-ab85-f5a07f0b04ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ordcp",
   "language": "python",
   "name": "ordcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
